{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R1T20UtPgEIE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Bottleneck unit testing available.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "feY03JQnNLDj"
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ErhCFUOSgkWt"
   },
   "outputs": [],
   "source": [
    "with open('multilabel_train_data.txt') as f:\n",
    "    data_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "30vzhnIkg39N"
   },
   "outputs": [],
   "source": [
    "#data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ylbVBjpzg5e5",
    "outputId": "96538235-384f-4b2e-b9fb-f2c13671f29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features are: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103]\n",
      "labels are: [ 2 13  5  6  1  3  7  8 12  0 11  4 10  9]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "features=[]\n",
    "\n",
    "for line in data_list:\n",
    "  line_list=line.split(' ')\n",
    "  labels.append(set(line_list[0].split(',')))\n",
    "  for j in line_list[1:-1]:\n",
    "    features.append(int(j.split(':')[0]))\n",
    "    \n",
    "features=np.array(features)\n",
    "label_set=set([])\n",
    "for i in labels:\n",
    "  label_set=set.union(label_set,i)\n",
    "label_arr=list(label_set)\n",
    "labels_arr=np.array([int(label_arr[i]) for i in range(len(label_arr))])\n",
    "\n",
    "features_arr=np.unique(features)\n",
    "print('features are:',features_arr) #feature space \n",
    "print('labels are:',labels_arr) # label space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQtAOe7Di1zG",
    "outputId": "548afe09-826a-4caa-a90a-37df3fa02ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y Array: array of labels:\n",
      "\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13]\n",
      "\n",
      " X array: array of features:\n",
      "\n",
      "[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103]\n"
     ]
    }
   ],
   "source": [
    "print('y Array: array of labels:\\n')\n",
    "labels_arr.sort()\n",
    "print(labels_arr)\n",
    "print('\\n X array: array of features:\\n')\n",
    "print(features_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbdP7qsFxxV5",
    "outputId": "29d8dbd3-705f-4de8-eca6-14884a84beac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in dataset: 14 \n",
      "\n",
      "Number of features in dataset: 103 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of classes in dataset:',len(labels_arr),'\\n')\n",
    "print('Number of features in dataset:',len(features_arr),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EGJTSTB25d-J",
    "outputId": "9cdf273d-2954-41a8-8bcc-04ab26af9944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points: 1500\n"
     ]
    }
   ],
   "source": [
    "# number of data points\n",
    "n=len(data_list)\n",
    "print('number of data points:',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CFpRZZ15iYf",
    "outputId": "22890de1-3da6-449e-f570-dfb05dcb0b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 103\n"
     ]
    }
   ],
   "source": [
    "#number of features\n",
    "d=len(features_arr)\n",
    "print('number of features:',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DHzDCt95kRE",
    "outputId": "f97cf335-7c52-42d9-8a8c-d2601f13697e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 103)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=np.array([0.0 for i in range(n*(d))]).reshape(n,d)\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15ByhcBB5nZo",
    "outputId": "16ef2653-603c-42d9-e362-747c206053a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[]\n",
    "for i in range(len(data_list)):\n",
    "  line=data_list[i]\n",
    "  line_list=line.split(' ')\n",
    "  labels.append(set(line_list[0].split(',')))\n",
    "  #print(i)\n",
    "  for j in line_list[1:-1]:\n",
    "    a=j.split(':')\n",
    "    #print(a,int(a[0])-1,a[1])\n",
    "    array[i,int(a[0])-1]=a[1]\n",
    "len(array) #value of data points corresponding to feature space   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Osd32eOx-8UD",
    "outputId": "ed7d40aa-aea9-4c0c-9b7f-57598b58fb87"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011858</td>\n",
       "      <td>-0.061636</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>0.089374</td>\n",
       "      <td>0.101825</td>\n",
       "      <td>-0.044525</td>\n",
       "      <td>0.222330</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>-0.053591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017531</td>\n",
       "      <td>-0.032930</td>\n",
       "      <td>-0.030487</td>\n",
       "      <td>0.009813</td>\n",
       "      <td>-0.002603</td>\n",
       "      <td>0.049288</td>\n",
       "      <td>-0.046913</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.115765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.018183</td>\n",
       "      <td>-0.045645</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.066467</td>\n",
       "      <td>-0.118108</td>\n",
       "      <td>0.105399</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.046744</td>\n",
       "      <td>-0.060929</td>\n",
       "      <td>0.284897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033050</td>\n",
       "      <td>-0.159394</td>\n",
       "      <td>0.125488</td>\n",
       "      <td>-0.149774</td>\n",
       "      <td>-0.148373</td>\n",
       "      <td>0.135500</td>\n",
       "      <td>0.047781</td>\n",
       "      <td>0.079903</td>\n",
       "      <td>0.065097</td>\n",
       "      <td>-0.165039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074145</td>\n",
       "      <td>-0.044487</td>\n",
       "      <td>0.048191</td>\n",
       "      <td>-0.006614</td>\n",
       "      <td>0.042746</td>\n",
       "      <td>0.025960</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.041714</td>\n",
       "      <td>0.048671</td>\n",
       "      <td>-0.038404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099730</td>\n",
       "      <td>0.145222</td>\n",
       "      <td>-0.102574</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.135860</td>\n",
       "      <td>-0.098214</td>\n",
       "      <td>-0.104915</td>\n",
       "      <td>-0.085630</td>\n",
       "      <td>0.174316</td>\n",
       "      <td>-0.022570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044432</td>\n",
       "      <td>-0.007842</td>\n",
       "      <td>0.018440</td>\n",
       "      <td>0.036639</td>\n",
       "      <td>0.243409</td>\n",
       "      <td>0.154859</td>\n",
       "      <td>0.128655</td>\n",
       "      <td>0.122329</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.106768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053067</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>-0.052333</td>\n",
       "      <td>-0.056184</td>\n",
       "      <td>-0.056243</td>\n",
       "      <td>-0.049476</td>\n",
       "      <td>-0.056670</td>\n",
       "      <td>0.120910</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>0.086152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051570</td>\n",
       "      <td>-0.016571</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.024296</td>\n",
       "      <td>0.155760</td>\n",
       "      <td>0.048347</td>\n",
       "      <td>-0.031283</td>\n",
       "      <td>0.133782</td>\n",
       "      <td>0.085081</td>\n",
       "      <td>-0.047716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107924</td>\n",
       "      <td>-0.086031</td>\n",
       "      <td>-0.098521</td>\n",
       "      <td>-0.086622</td>\n",
       "      <td>-0.091729</td>\n",
       "      <td>0.210266</td>\n",
       "      <td>0.110243</td>\n",
       "      <td>0.140546</td>\n",
       "      <td>0.182154</td>\n",
       "      <td>-0.101904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>-0.116754</td>\n",
       "      <td>-0.017859</td>\n",
       "      <td>-0.051158</td>\n",
       "      <td>0.015938</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.121055</td>\n",
       "      <td>-0.099059</td>\n",
       "      <td>0.023402</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057323</td>\n",
       "      <td>-0.125292</td>\n",
       "      <td>0.177598</td>\n",
       "      <td>-0.127144</td>\n",
       "      <td>-0.126141</td>\n",
       "      <td>0.046453</td>\n",
       "      <td>-0.070558</td>\n",
       "      <td>0.138768</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.016383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0.085234</td>\n",
       "      <td>0.049690</td>\n",
       "      <td>0.134850</td>\n",
       "      <td>0.091247</td>\n",
       "      <td>0.239547</td>\n",
       "      <td>0.140304</td>\n",
       "      <td>0.166942</td>\n",
       "      <td>0.050181</td>\n",
       "      <td>0.126451</td>\n",
       "      <td>0.135792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046560</td>\n",
       "      <td>0.071134</td>\n",
       "      <td>-0.041950</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.077935</td>\n",
       "      <td>-0.040123</td>\n",
       "      <td>-0.056090</td>\n",
       "      <td>-0.052238</td>\n",
       "      <td>-0.020390</td>\n",
       "      <td>0.085778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>-0.041893</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>-0.061547</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>-0.022888</td>\n",
       "      <td>0.023375</td>\n",
       "      <td>0.073267</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064247</td>\n",
       "      <td>0.158470</td>\n",
       "      <td>-0.061079</td>\n",
       "      <td>0.188122</td>\n",
       "      <td>0.182037</td>\n",
       "      <td>-0.056295</td>\n",
       "      <td>-0.075996</td>\n",
       "      <td>-0.072424</td>\n",
       "      <td>-0.039109</td>\n",
       "      <td>0.019538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>-0.058193</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>-0.081411</td>\n",
       "      <td>-0.033651</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.086514</td>\n",
       "      <td>-0.005469</td>\n",
       "      <td>0.033748</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>-0.044017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054680</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>-0.050850</td>\n",
       "      <td>-0.038719</td>\n",
       "      <td>0.178632</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>-0.062065</td>\n",
       "      <td>-0.017584</td>\n",
       "      <td>0.498207</td>\n",
       "      <td>-0.072177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>-0.128468</td>\n",
       "      <td>-0.003593</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.032379</td>\n",
       "      <td>-0.006359</td>\n",
       "      <td>-0.049659</td>\n",
       "      <td>-0.147537</td>\n",
       "      <td>-0.092815</td>\n",
       "      <td>0.050572</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020853</td>\n",
       "      <td>-0.044238</td>\n",
       "      <td>-0.065766</td>\n",
       "      <td>-0.062276</td>\n",
       "      <td>-0.069627</td>\n",
       "      <td>-0.010034</td>\n",
       "      <td>0.086035</td>\n",
       "      <td>-0.062728</td>\n",
       "      <td>-0.048271</td>\n",
       "      <td>-0.124432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows Ã— 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1         2         3         4         5         6         7    \\\n",
       "0    -0.011858 -0.061636  0.054392  0.021137  0.089374  0.101825 -0.044525   \n",
       "1    -0.018183 -0.045645  0.002001  0.066467 -0.118108  0.105399  0.004705   \n",
       "2     0.074145 -0.044487  0.048191 -0.006614  0.042746  0.025960  0.021290   \n",
       "3     0.044432 -0.007842  0.018440  0.036639  0.243409  0.154859  0.128655   \n",
       "4     0.051570 -0.016571  0.014702  0.024296  0.155760  0.048347 -0.031283   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1495 -0.116754 -0.017859 -0.051158  0.015938  0.015013  0.121055 -0.099059   \n",
       "1496  0.085234  0.049690  0.134850  0.091247  0.239547  0.140304  0.166942   \n",
       "1497  0.074028  0.014501 -0.041893  0.030209 -0.061547  0.022142 -0.022888   \n",
       "1498 -0.058193  0.502205 -0.081411 -0.033651  0.001250  0.086514 -0.005469   \n",
       "1499 -0.128468 -0.003593  0.039187  0.032379 -0.006359 -0.049659 -0.147537   \n",
       "\n",
       "           8         9         10   ...       94        95        96   \\\n",
       "0     0.222330  0.015575 -0.053591  ... -0.017531 -0.032930 -0.030487   \n",
       "1     0.046744 -0.060929  0.284897  ...  0.033050 -0.159394  0.125488   \n",
       "2     0.041714  0.048671 -0.038404  ... -0.099730  0.145222 -0.102574   \n",
       "3     0.122329  0.004179  0.106768  ... -0.053067  0.011885 -0.052333   \n",
       "4     0.133782  0.085081 -0.047716  ... -0.107924 -0.086031 -0.098521   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1495  0.023402  0.005873  0.019754  ...  0.057323 -0.125292  0.177598   \n",
       "1496  0.050181  0.126451  0.135792  ... -0.046560  0.071134 -0.041950   \n",
       "1497  0.023375  0.073267  0.019675  ... -0.064247  0.158470 -0.061079   \n",
       "1498  0.033748  0.007124 -0.044017  ... -0.054680 -0.000601 -0.050850   \n",
       "1499 -0.092815  0.050572  0.001716  ... -0.020853 -0.044238 -0.065766   \n",
       "\n",
       "           97        98        99        100       101       102       103  \n",
       "0     0.009813 -0.002603  0.049288 -0.046913 -0.000844  0.004983  0.115765  \n",
       "1    -0.149774 -0.148373  0.135500  0.047781  0.079903  0.065097 -0.165039  \n",
       "2     0.143100  0.135860 -0.098214 -0.104915 -0.085630  0.174316 -0.022570  \n",
       "3    -0.056184 -0.056243 -0.049476 -0.056670  0.120910 -0.028053  0.086152  \n",
       "4    -0.086622 -0.091729  0.210266  0.110243  0.140546  0.182154 -0.101904  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1495 -0.127144 -0.126141  0.046453 -0.070558  0.138768 -0.039471 -0.016383  \n",
       "1496  0.076210  0.077935 -0.040123 -0.056090 -0.052238 -0.020390  0.085778  \n",
       "1497  0.188122  0.182037 -0.056295 -0.075996 -0.072424 -0.039109  0.019538  \n",
       "1498 -0.038719  0.178632  0.151786 -0.062065 -0.017584  0.498207 -0.072177  \n",
       "1499 -0.062276 -0.069627 -0.010034  0.086035 -0.062728 -0.048271 -0.124432  \n",
       "\n",
       "[1500 rows x 103 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(array,columns=features_arr)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6iv-aa2Mbmjr"
   },
   "outputs": [],
   "source": [
    "data['labels']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "aIwycuVWfHyw",
    "outputId": "94ce8750-65a6-4c62-c9e7-d48ef8d537e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 104)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mvvu4c-sGusG",
    "outputId": "8e28f4be-7034-4c2a-d3da-17372d918364"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CpQM3IaGTLi",
    "outputId": "770d4969-3de8-4d6d-b6b7-14e3d8f2baf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of distinct classes 14\n"
     ]
    }
   ],
   "source": [
    "# number of labels\n",
    "k=len(labels_arr)\n",
    "print('number of distinct classes',k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQuBVUvSHPFO",
    "outputId": "d97002a1-fad3-4cf5-f22f-1aeed57d7f58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 14)\n"
     ]
    }
   ],
   "source": [
    "label_matrix=np.array([0 for i in range(n*k)]).reshape((n,k))\n",
    "for i in range(n):\n",
    "  for l in range(len(labels_arr)):\n",
    "    if str(labels_arr[l]) in data.labels[i]:\n",
    "      label_matrix[i][l]=1\n",
    "    else:\n",
    "      label_matrix[i][l]=-1\n",
    "print(label_matrix.shape)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnzCeBqp-PjS",
    "outputId": "0c572e45-9638-40d3-9811-4911dcb9c8b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "kWFSK3K4f-pn"
   },
   "outputs": [],
   "source": [
    "def lab(x,i):\n",
    "  if str(i) in x:\n",
    "    return 1\n",
    "  else:\n",
    "    return -1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MizZ51x-c7C",
    "outputId": "51eb0fc6-fabd-427e-ca3f-a9bae90867b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d8WV_RdSgNB9"
   },
   "outputs": [],
   "source": [
    "for i in labels_arr:\n",
    "  data[f'labels_{i}']=data['labels'].apply(lambda x: lab(x,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "viwkGcBggSZv",
    "outputId": "7a27c83a-71ba-4653-cd11-8f1932fffb35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 {7, 12, 11, 6}\n",
       "1                 {4, 3, 12, 11}\n",
       "2       {5, 6, 7, 12, 11, 4, 10}\n",
       "3                  {1, 2, 9, 10}\n",
       "4                 {1, 2, 12, 11}\n",
       "                  ...           \n",
       "1495              {1, 12, 0, 11}\n",
       "1496              {4, 3, 12, 11}\n",
       "1497              {4, 3, 12, 11}\n",
       "1498                      {7, 8}\n",
       "1499             {10, 12, 11, 9}\n",
       "Name: labels, Length: 1500, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4lCN6jUcF8F"
   },
   "source": [
    "$\\huge \\text{Adaboost function from scratch for binary classifier:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "diF-HX1K5b_B"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "6Pi-FJTBA4Z-"
   },
   "outputs": [],
   "source": [
    "def Adaboost_fit(data_X,data_y,rounds,depth):\n",
    "  weight_all=[]\n",
    "  epsilon_all=[]\n",
    "  alpha_all=[]\n",
    "  n=len(data_X) #number of data points\n",
    "  d=data_X.shape[1] #dimension of data\n",
    "  #initialization of weight vector\n",
    "  w=np.array([1/n for i in range(n)])\n",
    "  weight_all.append(w)\n",
    "  # rounds\n",
    "  T=rounds \n",
    "  # we need to store classifier\n",
    "  classifiers=[]\n",
    "  \n",
    "  for round in range(T):\n",
    "    weak_classifier=DecisionTreeClassifier(max_depth=depth)\n",
    "    weak_classifier.fit(data_X,data_y,sample_weight=w)\n",
    "    classifiers.append(weak_classifier)\n",
    "    #prediction\n",
    "    y_pred=weak_classifier.predict(data_X)\n",
    "    #epsilon value\n",
    "    epsilon=np.sum(w*(y_pred!=data_y))\n",
    "    epsilon_all.append(epsilon)\n",
    "    #alpha values\n",
    "    alpha=(1/2)*np.log((1-epsilon)/epsilon)\n",
    "    alpha_all.append(alpha)\n",
    "    # updatation the weight vector\n",
    "    w=w*np.exp(-1*alpha*y_pred*data_y)\n",
    "    # normalization of weight vector\n",
    "    w=w/np.sum(w)\n",
    "    # storing the w\n",
    "    weight_all.append(w)\n",
    "   \n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "  return alpha_all,weight_all,epsilon_all,classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDJ_Xrx0cVLB"
   },
   "source": [
    "$\\text{We use Decision tree classifier as a base classifier.}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VB4IzGKcd5I"
   },
   "source": [
    "$\\huge \\text{ prediction function}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "8C-ktgCi5lM8"
   },
   "outputs": [],
   "source": [
    "def AdaBoost_pred(data_X,alpha_all,classifiers):\n",
    "  T=len(alpha_all)\n",
    "  n=len(data_X)\n",
    "  predictions=[]\n",
    "  for i in range(T):\n",
    "    predictions.append(classifiers[i].predict(data_X))\n",
    "  pred=np.zeros(n)  \n",
    "  for i in range(T):\n",
    "    pred=pred+alpha_all[i]*predictions[i]\n",
    "    \n",
    "  return np.sign(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94BuOOcNcmho"
   },
   "source": [
    "$\\huge \\text{Accuracy function for binary classifier:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "5S8jrL755lt2"
   },
   "outputs": [],
   "source": [
    "def Accuracy_adaboost(prediction,actual_label):\n",
    "  return np.sum(prediction==actual_label)/len(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_v6xkE1cwvA"
   },
   "source": [
    "$\\text{We first apply our binary classifier first our label 0. Here we consider the label of data point is +1 is label 0 is present in its label set otherwise -1. }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X=np.array(data[data.columns[:-15]])\n",
    "data_y=np.array(data[data.columns[-2]])\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X,data_y,test_size=0.2,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.011858, -0.061636,  0.054392, ..., -0.000844,  0.004983,\n",
       "         0.115765],\n",
       "       [-0.018183, -0.045645,  0.002001, ...,  0.079903,  0.065097,\n",
       "        -0.165039],\n",
       "       [ 0.074145, -0.044487,  0.048191, ..., -0.08563 ,  0.174316,\n",
       "        -0.02257 ],\n",
       "       ...,\n",
       "       [ 0.074028,  0.014501, -0.041893, ..., -0.072424, -0.039109,\n",
       "         0.019538],\n",
       "       [-0.058193,  0.502205, -0.081411, ..., -0.017584,  0.498207,\n",
       "        -0.072177],\n",
       "       [-0.128468, -0.003593,  0.039187, ..., -0.062728, -0.048271,\n",
       "        -0.124432]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "6FUFON6Q8HXz"
   },
   "outputs": [],
   "source": [
    "alphas,weights,epsilons,classifiers=Adaboost_fit(X_train,y_train,90,depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d3LjdtIDQ6g",
    "outputId": "c909d653-01c7-44fc-d469-12920f1107ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# prediction over train data\n",
    "y_pred=AdaBoost_pred(X_train,alphas,classifiers)\n",
    "accuracy=Accuracy_adaboost(y_pred,np.array(y_train))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwQoF1WiCwkY",
    "outputId": "68fe6230-a805-4529-fa00-1f6c4691e12d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6766666666666666\n"
     ]
    }
   ],
   "source": [
    "# prediction over test data\n",
    "y_pred=AdaBoost_pred(X_test,alphas,classifiers)\n",
    "accuracy=Accuracy_adaboost(y_pred,np.array(y_test))\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yq5M9FESt8pp"
   },
   "source": [
    "$\\text{As we saw that our model is giving 100% accuracy over training data and 79% accuracy of test data.}$\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vhlcbg20uAaO"
   },
   "source": [
    "$\\huge \\text{Accuracy function (defined in Question)}$\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "eDFe2IEqGh6x"
   },
   "outputs": [],
   "source": [
    "def accuracy_set(y_prediction,y_actual):\n",
    "  n=len(y_actual)\n",
    "  sum=0\n",
    "  for i in range(n):\n",
    "    sum+=len(y_prediction[i].intersection(y_actual[i]))/len(y_prediction[i].union(y_actual[i]))\n",
    "    \n",
    "  return (1/n)*sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xT0ZgKmuDj2"
   },
   "source": [
    "$\\huge \\text{F1 score function (defined in Question)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "lHJaLIaVHk1a"
   },
   "outputs": [],
   "source": [
    "def F1_score(y_prediction,y_actual):\n",
    "  n=len(y_actual)\n",
    "  sum=0\n",
    "  for i in range(n):\n",
    "    sum+=len(y_prediction[i].intersection(y_actual[i]))/(len(y_prediction[i])+len(y_actual[i]))\n",
    "  return (1/n)*sum    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new=data.drop('labels',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=data[data.columns[:103]]\n",
    "Y_data=data[data.columns[103:]]\n",
    "Y_data.columns=['labels']+[1000+i for i in range(14)]\n",
    "train_x,test_x,train_y,test_y=train_test_split(X_data,Y_data,test_size=0.2)\n",
    "train_x=train_x.reset_index(drop=True)\n",
    "test_x=test_x.reset_index(drop=True)\n",
    "train_y=train_y.reset_index(drop=True)\n",
    "test_y=test_y.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 9, 1, 7, 6, 8, 4, 11, 3, 10, 5, 2, 12]\n"
     ]
    }
   ],
   "source": [
    "a=[i for i in range(13)]\n",
    "np.random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "HavtbGfSNImF"
   },
   "outputs": [],
   "source": [
    "\n",
    "def chainClassifier(data_x,data_y,k,shuffle_labels,depth_tree):\n",
    "    cls=[]\n",
    "    alp=[]\n",
    "    feature_req=[]\n",
    "    data_y=data_y[shuffle_labels]\n",
    "    data_new=pd.concat([data_x,data_y],axis=1)\n",
    "    for i in range(len(shuffle_labels)):\n",
    "        \n",
    "        x=np.array(data_new[data_new.columns[:-14+i]])\n",
    "        y=np.array(data_y[data_y.columns[i]])\n",
    "        \n",
    "        alphas,weights,epsilons,classifiers=Adaboost_fit(x,y,k,depth_tree)\n",
    "        alp.append(alphas)\n",
    "        cls.append(classifiers)\n",
    "        feature_req.append(data_new[data_new.columns[:-14+i]].columns)\n",
    "        \n",
    "    return cls,alp,feature_req\n",
    "def multi_chainClassifier_train(data_x,data_y,rounds,k,depth_tree):\n",
    "    labels=[1000+i for i in range(14)]\n",
    "    cls_dict={}\n",
    "    alp_dict={}\n",
    "    feature_dict={}\n",
    "    for rnd in range(rounds):\n",
    "        print('when round is:',rnd)\n",
    "        shuffle=labels.copy()\n",
    "        np.random.shuffle(shuffle)\n",
    "        classifier,alpha,features=chainClassifier(data_x,data_y,k,shuffle,depth_tree)\n",
    "        for i in range(len(shuffle)):\n",
    "            if shuffle[i]%1000 in cls_dict.keys():\n",
    "                cls_dict[shuffle[i]%1000].append(classifier[i])\n",
    "                alp_dict[shuffle[i]%1000].append(alpha[i])\n",
    "                feature_dict[shuffle[i]%1000].append(features[i])\n",
    "            else:\n",
    "                cls_dict[shuffle[i]%1000]=[classifier[i]]\n",
    "                alp_dict[shuffle[i]%1000]=[alpha[i]]\n",
    "                feature_dict[shuffle[i]%1000]=[features[i]]\n",
    "    return  cls_dict,alp_dict,feature_dict\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when round is: 0\n",
      "when round is: 1\n",
      "when round is: 2\n",
      "when round is: 3\n",
      "when round is: 4\n",
      "when round is: 5\n",
      "when round is: 6\n",
      "when round is: 7\n",
      "when round is: 8\n",
      "when round is: 9\n",
      "when round is: 10\n",
      "when round is: 11\n",
      "when round is: 12\n",
      "when round is: 13\n",
      "when round is: 14\n"
     ]
    }
   ],
   "source": [
    "cls_dict,alp_dict,feature_dict=multi_chainClassifier_train(train_x,train_y,rounds=15,k=90,depth_tree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge \\text{Inference over test and train dataset:}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge \\text{Train Data}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************\n",
      " for label: 0 \n",
      "*******************\n",
      "acc is: 0.9891666666666666\n",
      "************************\n",
      " for label: 1 \n",
      "*******************\n",
      "acc is: 0.9908333333333333\n",
      "************************\n",
      " for label: 2 \n",
      "*******************\n",
      "acc is: 0.9941666666666666\n",
      "************************\n",
      " for label: 3 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 4 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 5 \n",
      "*******************\n",
      "acc is: 0.995\n",
      "************************\n",
      " for label: 6 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 7 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 8 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 9 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 10 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 11 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "************************\n",
      " for label: 12 \n",
      "*******************\n",
      "acc is: 0.9666666666666667\n",
      "************************\n",
      " for label: 13 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "(14, 1200)\n",
      "**************************\n",
      " overall accuracy is: 0.9836742724867721\n",
      "**************************\n",
      " overall F1-Score is: 0.4952100496181378\n"
     ]
    }
   ],
   "source": [
    "label_pred=[]\n",
    "for label in range(14):\n",
    "    arr=[]\n",
    "    print('************************\\n for label:',label,'\\n*******************')\n",
    "    for i in range(10):\n",
    "        \n",
    "        features=list(feature_dict[label][i][103:])\n",
    "\n",
    "        x=pd.concat([train_x,train_y[features]],axis=1)\n",
    "        y=train_y[1000+label]\n",
    "        # prediction over train data\n",
    "        y_pred=AdaBoost_pred(x,alp_dict[label][i],cls_dict[label][i])\n",
    "        arr.append(y_pred)\n",
    "\n",
    "    # print(np.array(arr).shape)\n",
    "    pred=st.mode(arr).mode\n",
    "    label_pred.append(pred)\n",
    "    \n",
    "    accuracy=Accuracy_adaboost(pred,np.array(y))\n",
    "    print('acc is:',accuracy)\n",
    "label_pred=np.array(label_pred)\n",
    "print(label_pred.shape)\n",
    "\n",
    "predictions=label_pred.transpose()\n",
    "pd.DataFrame(label_pred.transpose(),columns=[i for i in range(14)])\n",
    "pred_set=[set([]) for i in range(len(predictions))]\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(14):\n",
    "        if predictions[i][j]==1:\n",
    "            \n",
    "            pred_set[i]=pred_set[i].union(set([str(j)]))\n",
    "            \n",
    "print('**************************\\n overall accuracy is:',accuracy_set(pred_set,np.array(train_y['labels'])))\n",
    "print('**************************\\n overall F1-Score is:',F1_score(pred_set,np.array(train_y['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892301587301586\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      " for label: 0 \n",
      "*******************\n",
      "acc is: 0.8266666666666667\n",
      "*********************\n",
      " for label: 1 \n",
      "*******************\n",
      "acc is: 0.75\n",
      "*********************\n",
      " for label: 2 \n",
      "*******************\n",
      "acc is: 0.8533333333333334\n",
      "*********************\n",
      " for label: 3 \n",
      "*******************\n",
      "acc is: 0.8933333333333333\n",
      "*********************\n",
      " for label: 4 \n",
      "*******************\n",
      "acc is: 0.9266666666666666\n",
      "*********************\n",
      " for label: 5 \n",
      "*******************\n",
      "acc is: 0.8566666666666667\n",
      "*********************\n",
      " for label: 6 \n",
      "*******************\n",
      "acc is: 0.9666666666666667\n",
      "*********************\n",
      " for label: 7 \n",
      "*******************\n",
      "acc is: 0.8566666666666667\n",
      "*********************\n",
      " for label: 8 \n",
      "*******************\n",
      "acc is: 0.93\n",
      "*********************\n",
      " for label: 9 \n",
      "*******************\n",
      "acc is: 0.92\n",
      "*********************\n",
      " for label: 10 \n",
      "*******************\n",
      "acc is: 0.9666666666666667\n",
      "*********************\n",
      " for label: 11 \n",
      "*******************\n",
      "acc is: 1.0\n",
      "*********************\n",
      " for label: 12 \n",
      "*******************\n",
      "acc is: 0.7633333333333333\n",
      "*********************\n",
      " for label: 13 \n",
      "*******************\n",
      "acc is: 0.99\n",
      "(14, 300)\n",
      "**************************\n",
      " overall accuracy is: 0.6863690476190474\n",
      "**************************\n",
      " overall F1-score is: 0.3874424605895196\n"
     ]
    }
   ],
   "source": [
    "label_pred=[]\n",
    "for label in range(14):\n",
    "    arr=[]\n",
    "    print('*********************\\n for label:',label,'\\n*******************')\n",
    "    for i in range(10):\n",
    "        \n",
    "        features=list(feature_dict[label][i][103:])\n",
    "\n",
    "        x=pd.concat([test_x,test_y[features]],axis=1)\n",
    "        y=test_y[1000+label]\n",
    "        # prediction over train data\n",
    "        y_pred=AdaBoost_pred(x,alp_dict[label][i],cls_dict[label][i])\n",
    "        arr.append(y_pred)\n",
    "\n",
    "    # print(np.array(arr).shape)\n",
    "    pred=st.mode(arr).mode\n",
    "    label_pred.append(pred)\n",
    "    \n",
    "    accuracy=Accuracy_adaboost(pred,np.array(y))\n",
    "    print('acc is:',accuracy)\n",
    "label_pred=np.array(label_pred)\n",
    "print(label_pred.shape)\n",
    "\n",
    "predictions=label_pred.transpose()\n",
    "pd.DataFrame(label_pred.transpose(),columns=[i for i in range(14)])\n",
    "pred_set=[set([]) for i in range(len(predictions))]\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(14):\n",
    "        if predictions[i][j]==1:\n",
    "            \n",
    "            pred_set[i]=pred_set[i].union(set([str(j)]))\n",
    "            \n",
    "print('**************************\\n overall accuracy is:',accuracy_set(pred_set,np.array(test_y['labels'])))\n",
    "print('**************************\\n overall F1-score is:',F1_score(pred_set,np.array(test_y['labels'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\huge \\text{Working over Private Dataset:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "xFBSrUWe--ZF"
   },
   "outputs": [],
   "source": [
    "with open('sample_multilabel_test_data.txt') as f:\n",
    "    data_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AXlE6PS--ZF",
    "outputId": "6d678dd4-3f93-48f6-a5f7-9e627f11bf14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features are: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103]\n",
      "labels are: [ 5  0  1  9 13 10 12  2  6  4  8 11  7  3]\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "features=[]\n",
    "\n",
    "for line in data_list:\n",
    "  line_list=line.split(' ')\n",
    "  labels.append(set(line_list[0].split(',')))\n",
    "  for j in line_list[1:-1]:\n",
    "    features.append(int(j.split(':')[0]))\n",
    "    \n",
    "features=np.array(features)\n",
    "label_set=set([])\n",
    "for i in labels:\n",
    "  label_set=set.union(label_set,i)\n",
    "label_arr=list(label_set)\n",
    "labels_arr=np.array([int(label_arr[i]) for i in range(len(label_arr))])\n",
    "\n",
    "features_arr=np.unique(features)\n",
    "print('features are:',features_arr)\n",
    "print('labels are:',labels_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86NJluVJ--ZF",
    "outputId": "0a2780d2-e557-4c32-bfd7-755783b058c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points: 50\n"
     ]
    }
   ],
   "source": [
    "# number of data points\n",
    "n=len(data_list)\n",
    "print('number of data points:',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qts7R99E--ZF",
    "outputId": "4a7f0680-4d27-4131-9cf7-b0438b32c64f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 103\n"
     ]
    }
   ],
   "source": [
    "#number of features\n",
    "d=len(features_arr)\n",
    "print('number of features:',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dspZ9sNI--ZG",
    "outputId": "2a05b25a-ab07-45d6-9315-a2470a38082c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 103)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=np.array([0.0 for i in range(n*(d))]).reshape(n,d)\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yZDTVim--ZG",
    "outputId": "67ea4237-14cc-4d55-a7ec-eea904950d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[]\n",
    "for i in range(len(data_list)):\n",
    "  line=data_list[i]\n",
    "  line_list=line.split(' ')\n",
    "  labels.append(set(line_list[0].split(',')))\n",
    "  #print(i)\n",
    "  for j in line_list[1:-1]:\n",
    "    a=j.split(':')\n",
    "    #print(a,int(a[0])-1,a[1])\n",
    "    array[i,int(a[0])-1]=a[1]\n",
    "len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "-O1V2SLf--ZG"
   },
   "outputs": [],
   "source": [
    "labels_arr.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "NAlmZR-f--ZG"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(array,columns=features_arr)\n",
    "df['labels']=labels\n",
    "for i in labels_arr:\n",
    "  df[f'labels_{i}']=df['labels'].apply(lambda x: lab(x,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "EgKPyI6P--ZG",
    "outputId": "abf2aa29-889e-4aa3-c9c6-f2e9f1d073ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>labels_4</th>\n",
       "      <th>labels_5</th>\n",
       "      <th>labels_6</th>\n",
       "      <th>labels_7</th>\n",
       "      <th>labels_8</th>\n",
       "      <th>labels_9</th>\n",
       "      <th>labels_10</th>\n",
       "      <th>labels_11</th>\n",
       "      <th>labels_12</th>\n",
       "      <th>labels_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097750</td>\n",
       "      <td>0.059746</td>\n",
       "      <td>0.115902</td>\n",
       "      <td>0.075859</td>\n",
       "      <td>0.097757</td>\n",
       "      <td>0.214842</td>\n",
       "      <td>0.215689</td>\n",
       "      <td>0.177362</td>\n",
       "      <td>0.178295</td>\n",
       "      <td>0.116535</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017362</td>\n",
       "      <td>-0.004442</td>\n",
       "      <td>0.071415</td>\n",
       "      <td>0.080824</td>\n",
       "      <td>-0.158254</td>\n",
       "      <td>-0.069842</td>\n",
       "      <td>-0.165107</td>\n",
       "      <td>-0.029324</td>\n",
       "      <td>0.142120</td>\n",
       "      <td>0.042755</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007123</td>\n",
       "      <td>-0.118310</td>\n",
       "      <td>0.134876</td>\n",
       "      <td>-0.004037</td>\n",
       "      <td>0.132463</td>\n",
       "      <td>0.126321</td>\n",
       "      <td>0.117789</td>\n",
       "      <td>-0.043311</td>\n",
       "      <td>-0.002460</td>\n",
       "      <td>-0.014554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.157322</td>\n",
       "      <td>-0.066659</td>\n",
       "      <td>-0.191130</td>\n",
       "      <td>-0.097811</td>\n",
       "      <td>-0.223990</td>\n",
       "      <td>-0.053608</td>\n",
       "      <td>-0.170721</td>\n",
       "      <td>-0.134466</td>\n",
       "      <td>-0.069921</td>\n",
       "      <td>0.099598</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.159182</td>\n",
       "      <td>0.299849</td>\n",
       "      <td>0.116136</td>\n",
       "      <td>0.076483</td>\n",
       "      <td>-0.046788</td>\n",
       "      <td>0.076437</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1         2         3         4         5         6         7  \\\n",
       "0  0.097750  0.059746  0.115902  0.075859  0.097757  0.214842  0.215689   \n",
       "1  0.017362 -0.004442  0.071415  0.080824 -0.158254 -0.069842 -0.165107   \n",
       "2 -0.007123 -0.118310  0.134876 -0.004037  0.132463  0.126321  0.117789   \n",
       "3 -0.157322 -0.066659 -0.191130 -0.097811 -0.223990 -0.053608 -0.170721   \n",
       "4  0.063291  0.159182  0.299849  0.116136  0.076483 -0.046788  0.076437   \n",
       "\n",
       "          8         9        10  ...  labels_4  labels_5  labels_6  labels_7  \\\n",
       "0  0.177362  0.178295  0.116535  ...        -1        -1        -1        -1   \n",
       "1 -0.029324  0.142120  0.042755  ...         1        -1        -1        -1   \n",
       "2 -0.043311 -0.002460 -0.014554  ...         1         1        -1        -1   \n",
       "3 -0.134466 -0.069921  0.099598  ...        -1        -1        -1        -1   \n",
       "4  0.003833  0.003026  0.022628  ...        -1        -1        -1        -1   \n",
       "\n",
       "   labels_8  labels_9  labels_10  labels_11  labels_12  labels_13  \n",
       "0        -1        -1         -1          1          1         -1  \n",
       "1        -1        -1         -1          1          1         -1  \n",
       "2        -1        -1         -1         -1         -1         -1  \n",
       "3        -1         1          1          1          1         -1  \n",
       "4        -1        -1         -1          1          1         -1  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "L82HatC_--ZG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************\n",
      " for label: 0 \n",
      "*******************\n",
      "acc is: 0.86\n",
      "*********************\n",
      " for label: 1 \n",
      "*******************\n",
      "acc is: 0.76\n",
      "*********************\n",
      " for label: 2 \n",
      "*******************\n",
      "acc is: 0.9\n",
      "*********************\n",
      " for label: 3 \n",
      "*******************\n",
      "acc is: 0.94\n",
      "*********************\n",
      " for label: 4 \n",
      "*******************\n",
      "acc is: 0.84\n",
      "*********************\n",
      " for label: 5 \n",
      "*******************\n",
      "acc is: 0.76\n",
      "*********************\n",
      " for label: 6 \n",
      "*******************\n",
      "acc is: 0.96\n",
      "*********************\n",
      " for label: 7 \n",
      "*******************\n",
      "acc is: 0.94\n",
      "*********************\n",
      " for label: 8 \n",
      "*******************\n",
      "acc is: 0.98\n",
      "*********************\n",
      " for label: 9 \n",
      "*******************\n",
      "acc is: 0.86\n",
      "*********************\n",
      " for label: 10 \n",
      "*******************\n",
      "acc is: 0.94\n",
      "*********************\n",
      " for label: 11 \n",
      "*******************\n",
      "acc is: 0.96\n",
      "*********************\n",
      " for label: 12 \n",
      "*******************\n",
      "acc is: 0.74\n",
      "*********************\n",
      " for label: 13 \n",
      "*******************\n",
      "acc is: 0.98\n",
      "(14, 50)\n",
      "**************************\n",
      " overall accuracy is: 0.6581587301587303\n",
      "**************************\n",
      " overall F1-score is: 0.37445659895659894\n"
     ]
    }
   ],
   "source": [
    "test_data=df.copy()\n",
    "\n",
    "inf_data_x=test_data[test_data.columns[:-15]]\n",
    "inf_data_y=test_data[test_data.columns[-14:]]\n",
    "\n",
    "inf_data_y.columns=[1000+i for i in range(14)]\n",
    "\n",
    "inf_set_y=test_data[test_data.columns[-15]]\n",
    "label_pred=[]\n",
    "for label in range(14):\n",
    "    arr=[]\n",
    "    print('*********************\\n for label:',label,'\\n*******************')\n",
    "    for i in range(10):\n",
    "        \n",
    "        features=list(feature_dict[label][i][103:])\n",
    "\n",
    "        x=pd.concat([inf_data_x,inf_data_y[features]],axis=1)\n",
    "        y=inf_data_y[1000+label]\n",
    "        # prediction over train data\n",
    "        y_pred=AdaBoost_pred(x,alp_dict[label][i],cls_dict[label][i])\n",
    "        arr.append(y_pred)\n",
    "\n",
    "    # print(np.array(arr).shape)\n",
    "    pred=st.mode(arr).mode\n",
    "    label_pred.append(pred)\n",
    "    \n",
    "    accuracy=Accuracy_adaboost(pred,np.array(y))\n",
    "    print('acc is:',accuracy)\n",
    "label_pred=np.array(label_pred)\n",
    "print(label_pred.shape)\n",
    "\n",
    "predictions=label_pred.transpose()\n",
    "pd.DataFrame(label_pred.transpose(),columns=[i for i in range(14)])\n",
    "pred_set=[set([]) for i in range(len(predictions))]\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(14):\n",
    "        if predictions[i][j]==1:\n",
    "            \n",
    "            pred_set[i]=pred_set[i].union(set([str(j)]))\n",
    "            \n",
    "print('**************************\\n overall accuracy is:',accuracy_set(pred_set,np.array(inf_set_y)))\n",
    "print('**************************\\n overall F1-score is:',F1_score(pred_set,np.array(inf_set_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_data.pkl', 'rb') as f:\n",
    "    my_function = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_function['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump(multitask_Adaboost_training_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'rb') as f:\n",
    "    my_function = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multitask_Adaboost_training_model(data, k=90)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " my_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
